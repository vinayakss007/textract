{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fitz in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.0.1.dev2)\n",
      "Requirement already satisfied: configobj in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from fitz) (5.0.8)\n",
      "Requirement already satisfied: configparser in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from fitz) (7.0.0)\n",
      "Requirement already satisfied: httplib2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from fitz) (0.22.0)\n",
      "Requirement already satisfied: nibabel in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from fitz) (5.2.1)\n",
      "Requirement already satisfied: nipype in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from fitz) (1.8.6)\n",
      "Requirement already satisfied: numpy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from fitz) (1.26.2)\n",
      "Requirement already satisfied: pandas in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from fitz) (2.1.4)\n",
      "Requirement already satisfied: pyxnat in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from fitz) (1.6.2)\n",
      "Requirement already satisfied: scipy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from fitz) (1.11.4)\n",
      "Requirement already satisfied: six in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from configobj->fitz) (1.16.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from httplib2->fitz) (3.1.2)\n",
      "Requirement already satisfied: packaging>=17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nibabel->fitz) (24.0)\n",
      "Requirement already satisfied: click>=6.6.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nipype->fitz) (8.1.7)\n",
      "Requirement already satisfied: networkx>=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nipype->fitz) (3.3)\n",
      "Requirement already satisfied: prov>=1.5.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nipype->fitz) (2.0.1)\n",
      "Requirement already satisfied: pydot>=1.2.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nipype->fitz) (2.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nipype->fitz) (2.9.0.post0)\n",
      "Requirement already satisfied: rdflib>=5.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nipype->fitz) (6.3.2)\n",
      "Requirement already satisfied: simplejson>=3.8.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nipype->fitz) (3.19.2)\n",
      "Requirement already satisfied: traits!=5.0,<6.4,>=4.6 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nipype->fitz) (6.3.2)\n",
      "Requirement already satisfied: filelock>=3.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nipype->fitz) (3.14.0)\n",
      "Requirement already satisfied: etelemetry>=0.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nipype->fitz) (0.3.1)\n",
      "Requirement already satisfied: looseversion in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from nipype->fitz) (1.3.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->fitz) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->fitz) (2024.1)\n",
      "Requirement already satisfied: lxml>=4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pyxnat->fitz) (5.2.2)\n",
      "Requirement already satisfied: requests>=2.20 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pyxnat->fitz) (2.32.3)\n",
      "Requirement already satisfied: pathlib>=1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pyxnat->fitz) (1.0.1)\n",
      "Requirement already satisfied: ci-info>=0.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from etelemetry>=0.2.0->nipype->fitz) (0.3.0)\n",
      "Requirement already satisfied: isodate<0.7.0,>=0.6.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rdflib>=5.0.0->nipype->fitz) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.20->pyxnat->fitz) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.20->pyxnat->fitz) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.20->pyxnat->fitz) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests>=2.20->pyxnat->fitz) (2024.6.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install fitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting frontend\n",
      "  Downloading frontend-0.0.3-py3-none-any.whl.metadata (847 bytes)\n",
      "Requirement already satisfied: starlette>=0.12.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from frontend) (0.37.2)\n",
      "Requirement already satisfied: uvicorn>=0.7.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from frontend) (0.30.1)\n",
      "Collecting itsdangerous>=1.1.0 (from frontend)\n",
      "  Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting aiofiles (from frontend)\n",
      "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from starlette>=0.12.0->frontend) (4.4.0)\n",
      "Requirement already satisfied: click>=7.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from uvicorn>=0.7.1->frontend) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from uvicorn>=0.7.1->frontend) (0.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from uvicorn>=0.7.1->frontend) (4.12.1)\n",
      "Requirement already satisfied: idna>=2.8 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette>=0.12.0->frontend) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette>=0.12.0->frontend) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette>=0.12.0->frontend) (1.2.1)\n",
      "Downloading frontend-0.0.3-py3-none-any.whl (32 kB)\n",
      "Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: itsdangerous, aiofiles, frontend\n",
      "Successfully installed aiofiles-23.2.1 frontend-0.0.3 itsdangerous-2.2.0\n"
     ]
    }
   ],
   "source": [
    "! pip install frontend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Directory 'static/' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfitz\u001b[39;00m  \u001b[38;5;66;03m# PyMuPDF\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_text_from_pdf\u001b[39m(pdf_path):\n\u001b[1;32m      4\u001b[0m     doc \u001b[38;5;241m=\u001b[39m fitz\u001b[38;5;241m.\u001b[39mopen(pdf_path)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/fitz/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfrontend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtools\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpath\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mop\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/frontend/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevents\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponents\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/frontend/events/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclipboard\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevent_mixins\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhash_change\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/frontend/events/clipboard.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevent_mixins\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ClipboardDataMixin\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdom\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Event\n\u001b[1;32m      4\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClipboardEvent\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mClipboardEvent\u001b[39;00m(Event, ClipboardDataMixin):\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/frontend/dom.py:439\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m    436\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 439\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dispatcher\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/frontend/dispatcher.py:15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstarlette\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mendpoints\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WebSocketEndpoint\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstarlette\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwebsockets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WebSocket\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config, server\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01masync_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m later_await\n\u001b[1;32m     18\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreact\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/frontend/server.py:24\u001b[0m\n\u001b[1;32m     21\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroute\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrun\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     23\u001b[0m app: Any \u001b[38;5;241m=\u001b[39m Starlette(debug\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mDEBUG)\n\u001b[0;32m---> 24\u001b[0m app\u001b[38;5;241m.\u001b[39mmount(config\u001b[38;5;241m.\u001b[39mSTATIC_ROUTE, \u001b[43mStaticFiles\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSTATIC_DIRECTORY\u001b[49m\u001b[43m)\u001b[49m, name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mSTATIC_NAME)\n\u001b[1;32m     25\u001b[0m app\u001b[38;5;241m.\u001b[39madd_middleware(GZipMiddleware)\n\u001b[1;32m     26\u001b[0m app\u001b[38;5;241m.\u001b[39madd_middleware(\n\u001b[1;32m     27\u001b[0m     CORSMiddleware,\n\u001b[1;32m     28\u001b[0m     allow_origins\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m     allow_headers\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     32\u001b[0m )\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/starlette/staticfiles.py:59\u001b[0m, in \u001b[0;36mStaticFiles.__init__\u001b[0;34m(self, directory, packages, html, check_dir, follow_symlink)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfollow_symlink \u001b[38;5;241m=\u001b[39m follow_symlink\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_dir \u001b[38;5;129;01mand\u001b[39;00m directory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(directory):\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDirectory \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirectory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m does not exist\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Directory 'static/' does not exist"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "pdf_path = '/teamspace/studios/this_studio/textract/paper/data-06-00078-v2.pdf'\n",
    "extracted_text = extract_text_from_pdf(pdf_path)\n",
    "print(extracted_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page of 1, rut\n",
      "Invoice for Db34FA16N Apr 22, 2016\n",
      "\n",
      "Retail/TaxInvoice/Cash Memorandum\n",
      "Sold By\n",
      "\n",
      "Green Mobiles\n",
      "\n",
      "No. 369, 13th Cross, 30th Main,\n",
      "\n",
      "Banashankan 2na Stage\n",
      "\n",
      "Songalre- 960070 DOSSFAAEN /a of 1 o// tdnecodselgibe\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "LVAT/TIN Number: 29130670647 Invoice Number: KA-QSAM-137308031-352\n",
      "CST Number: 29130670547\n",
      "Billing Address ‘Shipping Address\n",
      "emant venkata raghavendra femani venkata raghavencra\n",
      "TO1-A, sector t Sor-a, sector t\n",
      "Uikkunagaram , vizag stee! plant ‘kkunagaram , vizag stee! plant\n",
      "VISAKHAPATHIAM, AP ~ 530032 VISAKHAPATNAM, AP ~ 530032\n",
      "Nature of Transaction: Sele\n",
      "Order 1 403-1854494-1688325 This is a computer generated invoice\n",
      "GI DESCRIPTION GROSS DISCOUNT NETAMOUNT TAX TAX TAX AMOUNT\n",
      "AMOUNT (laxinelusive) TYPE RATE (Induded in\n",
      "net)\n",
      "1 Agus Zenfone Max ZCSSOKL (Black, _—_s. 9,999.00, Rs.9,999.00 CST 5.5% Rs. $21.27\n",
      "seca)\n",
      "XODOHOK33V\n",
      "Serial Number=353382070605923\n",
      "Shipping Rs.40.00 Rs. -40.00 Rs. 0.00 CST _ 5.5% Rs, 0.00\n",
      "TOTAL TOTAL __FINALNET TAX TAX TAX\n",
      "GROSS DISCOUNT AMOUNT ‘TPE RATE AMOUNT\n",
      "AMOUNT\n",
      "Rs Rs. 40.00 Rs.9,999.00  CST@5.5% Rs. 521.27\n",
      "10,039.00\n",
      "1 We hereby certify that my / our registration certificate under the For Green Mobiles\n",
      "\n",
      "Karnataka Value Added Tax Act, 2003 i in force on the date on which the\n",
      "\n",
      "sale of the goods speatied in this tax involce is made by me / us and tat\n",
      "{the transaction of sale covered by this tax invoice Nas bean effected by\n",
      "\n",
      "me/us and ft shall be accounted for in the tumover of sales while fling of\n",
      "\n",
      "dssalbn Sia sce Vane pavahc on oe Tasha boc pr es\n",
      "ra SIE\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "Registered Acdress for Groen Mobiles, 369 13th Cross 30th Main, Banashankari 2nd Stage, Bangalore - 560070, Karnataka, IN\n",
      "\n",
      " \n",
      "\n",
      "To return an item, visit http://www.amazon.jn/ returns\n",
      "For more information on your orders, visit http,\n",
      "www amazonin/your-account al Purchase made on\n",
      "\n",
      "Db34FAf6n /-1 of 1 -// std-in-cod-elighble/ 0422-16:48/ 0426-08:30\n",
      "\n",
      " \n",
      "\n",
      "amazonin\n",
      "—\n",
      "\f\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "def extract_text_from_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    text = pytesseract.image_to_string(image)\n",
    "    return text\n",
    "\n",
    "image_path = '/teamspace/studios/this_studio/textract/data/train/Amazon--1-_jpg.rf.dad58854ca48c18071139e87b63c816e.jpg'\n",
    "extracted_text = extract_text_from_image(image_path)\n",
    "print(extracted_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Text mining - Wikipedia\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Jump to content\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Main menu\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Main menu\n",
      "move to sidebar\n",
      "hide\n",
      "\n",
      "\n",
      "\n",
      "\t\tNavigation\n",
      "\t\n",
      "\n",
      "\n",
      "Main pageContentsCurrent eventsRandom articleAbout WikipediaContact usDonate\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\tContribute\n",
      "\t\n",
      "\n",
      "\n",
      "HelpLearn to editCommunity portalRecent changesUpload file\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Search\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Search\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Appearance\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Create account\n",
      "\n",
      "Log in\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Personal tools\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Create account Log in\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\tPages for logged out editors learn more\n",
      "\n",
      "\n",
      "\n",
      "ContributionsTalk\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Contents\n",
      "move to sidebar\n",
      "hide\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(Top)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "1\n",
      "Text analytics\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2\n",
      "Text analysis processes\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "3\n",
      "Applications\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Toggle Applications subsection\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "3.1\n",
      "Security applications\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "3.2\n",
      "Biomedical applications\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "3.3\n",
      "Software applications\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "3.4\n",
      "Online media applications\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "3.5\n",
      "Business and marketing applications\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "3.6\n",
      "Sentiment analysis\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "3.7\n",
      "Scientific literature mining and academic applications\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "3.7.1\n",
      "Methods for scientific literature mining\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "3.8\n",
      "Digital humanities and computational sociology\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "4\n",
      "Software\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "5\n",
      "Intellectual property law\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Toggle Intellectual property law subsection\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "5.1\n",
      "Situation in Europe\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "5.2\n",
      "Situation in the United States\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "5.3\n",
      "Situation in Australia\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "6\n",
      "Implications\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "7\n",
      "See also\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "8\n",
      "References\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Toggle References subsection\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "8.1\n",
      "Citations\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "8.2\n",
      "Sources\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "9\n",
      "External links\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Toggle the table of contents\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Text mining\n",
      "\n",
      "\n",
      "\n",
      "32 languages\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "العربيةБългарскиBosanskiCatalàČeštinaDeutschEestiΕλληνικάEspañolEuskaraفارسیFrançais한국어Bahasa IndonesiaItalianoעבריתMagyarNederlands日本語Oʻzbekcha / ўзбекчаPolskiPortuguêsРусскийSlovenščinaSuomiSvenskaไทยTürkçeУкраїнськаTiếng Việt粵語中文\n",
      "\n",
      "Edit links\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ArticleTalk\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "English\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ReadEditView history\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Tools\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Tools\n",
      "move to sidebar\n",
      "hide\n",
      "\n",
      "\n",
      "\n",
      "\t\tActions\n",
      "\t\n",
      "\n",
      "\n",
      "ReadEditView history\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\tGeneral\n",
      "\t\n",
      "\n",
      "\n",
      "What links hereRelated changesUpload fileSpecial pagesPermanent linkPage informationCite this pageGet shortened URLDownload QR codeWikidata item\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\tPrint/export\n",
      "\t\n",
      "\n",
      "\n",
      "Download as PDFPrintable version\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\tIn other projects\n",
      "\t\n",
      "\n",
      "\n",
      "Wikimedia Commons\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Appearance\n",
      "move to sidebar\n",
      "hide\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "From Wikipedia, the free encyclopedia\n",
      "\n",
      "\n",
      "Process of analysing text to extract information from it\n",
      "Text mining, text data mining (TDM) or text analytics is the process of deriving high-quality information from text. It involves \"the discovery by computer of new, previously unknown information, by automatically extracting information from different written resources.\"[1] Written resources may include websites, books, emails, reviews, and articles. High-quality information is typically obtained by devising patterns and trends by means such as statistical pattern learning. According to Hotho et al. (2005) we can distinguish between three different perspectives of text mining: information extraction, data mining, and a knowledge discovery in databases (KDD) process.[2] Text mining usually involves the process of structuring the input text (usually parsing, along with the addition of some derived linguistic features and the removal of others, and subsequent insertion into a database), deriving patterns within the structured data, and finally evaluation and interpretation of the output. 'High quality' in text mining usually refers to some combination of relevance, novelty, and interest. Typical text mining tasks include text categorization, text clustering, concept/entity extraction, production of granular taxonomies, sentiment analysis, document summarization, and entity relation modeling (i.e., learning relations between named entities).\n",
      "Text analysis involves information retrieval, lexical analysis to study word frequency distributions, pattern recognition, tagging/annotation, information extraction, data mining techniques including link and association analysis, visualization, and predictive analytics. The overarching goal is, essentially, to turn text into data for analysis, via the application of natural language processing (NLP), different types of algorithms and analytical methods. An important phase of this process is the interpretation of the gathered information.\n",
      "A typical application is to scan a set of documents written in a natural language and either model the document set for predictive classification purposes or populate a database or search index with the information extracted. The document is the basic element when starting with text mining. Here, we define a document as a unit of textual data, which normally exists in many types of collections.[3]\n",
      "\n",
      "\n",
      "Text analytics[edit]\n",
      "See also: List of text mining methods\n",
      "Text analytics describes a set of linguistic, statistical, and machine learning techniques that model and structure the information content of textual sources for business intelligence, exploratory data analysis, research, or investigation.[4] The term is roughly synonymous with text mining; indeed, Ronen Feldman modified a 2000 description of \"text mining\"[5] in 2004 to describe \"text analytics\".[6] The latter term is now used more frequently in business settings while \"text mining\" is used in some of the earliest application areas, dating to the 1980s,[7] notably life-sciences research and government intelligence.\n",
      "The term text analytics also describes that application of text analytics to respond to business problems, whether independently or in conjunction with query and analysis of fielded, numerical data. It is a truism that 80 percent of business-relevant information originates in unstructured form, primarily text.[8] These techniques and processes discover and present knowledge – facts, business rules, and relationships – that is otherwise locked in textual form, impenetrable to automated processing.\n",
      "\n",
      "Text analysis processes[edit]\n",
      "Subtasks—components of a larger text-analytics effort—typically include:\n",
      "\n",
      "Dimensionality reduction is important technique for pre-processing data. Technique is used to identify the root word for actual words and reduce the size of the text data.[citation needed]\n",
      "Information retrieval or identification of a corpus is a preparatory step: collecting or identifying a set of textual materials, on the Web or held in a file system, database, or content corpus manager, for analysis.\n",
      "Although some text analytics systems apply exclusively advanced statistical methods, many others apply more extensive natural language processing, such as part of speech tagging, syntactic parsing, and other types of linguistic analysis.[9]\n",
      "Named entity recognition is the use of gazetteers or statistical techniques to identify named text features: people, organizations, place names, stock ticker symbols, certain abbreviations, and so on.\n",
      "Disambiguation—the use of contextual clues—may be required to decide where, for instance, \"Ford\" can refer to a former U.S. president, a vehicle manufacturer, a movie star, a river crossing, or some other entity.[10]\n",
      "Recognition of Pattern Identified Entities: Features such as telephone numbers, e-mail addresses, quantities (with units) can be discerned via regular expression or other pattern matches.\n",
      "Document clustering: identification of sets of similar text documents.[11]\n",
      "Coreference: identification of noun phrases and other terms that refer to the same object.\n",
      "Relationship, fact, and event Extraction: identification of associations among entities and other information in texts.\n",
      "Sentiment analysis involves discerning subjective (as opposed to factual) material and extracting various forms of attitudinal information: sentiment, opinion, mood, and emotion. Text analytics techniques help analyze sentiment at the entity, concept, or topic level and distinguish opinion holders and objects.[12]\n",
      "Quantitative text analysis is a set of techniques stemming from the social sciences where either a human judge or a computer extracts semantic or grammatical relationships between words in order to find out the meaning or stylistic patterns of, usually, a casual personal text for the purpose of psychological profiling etc.[13]\n",
      "Pre-processing usually involves tasks such as tokenization, filtering and stemming.\n",
      "Applications[edit]\n",
      "Text mining technology is now broadly applied to a wide variety of government, research, and business needs. All these groups may use text mining for records management and searching documents relevant to their daily activities. Legal professionals may use text mining for e-discovery, for example. Governments and military groups use text mining for national security and intelligence purposes. Scientific researchers incorporate text mining approaches into efforts to organize large sets of text data (i.e., addressing the problem of unstructured data), to determine ideas communicated through text (e.g., sentiment analysis in social media[14][15][16]) and to support scientific discovery in fields such as the life sciences and bioinformatics. In business, applications are used to support competitive intelligence and automated ad placement, among numerous other activities.\n",
      "\n",
      "Security applications[edit]\n",
      "Many text mining software packages are marketed for security applications, especially monitoring and analysis of online plain text sources such as Internet news, blogs, etc. for national security purposes.[17] It is also involved in the study of text encryption/decryption.\n",
      "\n",
      "Biomedical applications[edit]\n",
      "Main article: Biomedical text mining\n",
      "An example of a text mining protocol used in a study of protein-protein complexes, or protein docking.[18]\n",
      "A range of text mining applications in the biomedical literature has been described,[19] including computational approaches to assist with studies in protein docking,[20] protein interactions,[21][22] and protein-disease associations.[23] In addition, with large patient textual datasets in the clinical field, datasets of demographic information in population studies and adverse event reports, text mining can facilitate clinical studies and precision medicine. Text mining algorithms can facilitate the stratification and indexing of specific clinical events in large patient textual datasets of symptoms, side effects, and comorbidities from electronic health records, event reports, and reports from specific diagnostic tests.[24] One online text mining application in the biomedical literature is PubGene, a publicly accessible search engine that combines biomedical text mining with network visualization.[25][26] GoPubMed is a knowledge-based search engine for biomedical texts. Text mining techniques also enable us to extract unknown knowledge from unstructured documents in the clinical domain[27]\n",
      "\n",
      "Software applications[edit]\n",
      "Text mining methods and software is also being researched and developed by major firms, including IBM and Microsoft, to further automate the mining and analysis processes, and by different firms working in the area of search and indexing in general as a way to improve their results. Within the public sector, much effort has been concentrated on creating software for tracking and monitoring terrorist activities.[28] For study purposes, Weka software is one of the most popular options in the scientific world, acting as an excellent entry point for beginners. For Python programmers, there is an excellent toolkit called NLTK for more general purposes. For more advanced programmers, there's also the Gensim library, which focuses on word embedding-based text representations.\n",
      "\n",
      "Online media applications[edit]\n",
      "Text mining is being used by large media companies, such as the Tribune Company, to clarify information and to provide readers with greater search experiences, which in turn increases site \"stickiness\" and revenue. Additionally, on the back end, editors are benefiting by being able to share, associate and package news across properties, significantly increasing opportunities to monetize content.\n",
      "\n",
      "Business and marketing applications[edit]\n",
      "Text analytics is being used in business, particularly, in marketing, such as in customer relationship management.[29] Coussement and Van den Poel (2008)[30][31] apply it to improve predictive analytics models for customer churn (customer attrition).[30] Text mining is also being applied in stock returns prediction.[32]\n",
      "\n",
      "Sentiment analysis[edit]\n",
      "Sentiment analysis may involve analysis of products such as movies, books, or hotel reviews for estimating how favorable a review is for the product.[33]\n",
      "Such an analysis may need a labeled data set or labeling of the affectivity of words.\n",
      "Resources for affectivity of words and concepts have been made for WordNet[34] and ConceptNet,[35] respectively.\n",
      "Text has been used to detect emotions in the related area of affective computing.[36] Text based approaches to affective computing have been used on multiple corpora such as students evaluations, children stories and news stories.\n",
      "\n",
      "Scientific literature mining and academic applications[edit]\n",
      "The issue of text mining is of importance to publishers who hold large databases of information needing indexing for retrieval. This is especially true in scientific disciplines, in which highly specific information is often contained within the written text. Therefore, initiatives have been taken such as Nature's proposal for an Open Text Mining Interface (OTMI) and the National Institutes of Health's common Journal Publishing Document Type Definition (DTD) that would provide semantic cues to machines to answer specific queries contained within the text without removing publisher barriers to public access.\n",
      "Academic institutions have also become involved in the text mining initiative:\n",
      "\n",
      "The National Centre for Text Mining (NaCTeM), is the first publicly funded text mining centre in the world. NaCTeM is operated by the University of Manchester[37] in close collaboration with the Tsujii Lab,[38] University of Tokyo.[39] NaCTeM provides customised tools, research facilities and offers advice to the academic community. They are funded by the Joint Information Systems Committee (JISC) and two of the UK research councils (EPSRC & BBSRC). With an initial focus on text mining in the biological and biomedical sciences, research has since expanded into the areas of social sciences.\n",
      "In the United States, the School of Information at University of California, Berkeley is developing a program called BioText to assist biology researchers in text mining and analysis.\n",
      "The Text Analysis Portal for Research (TAPoR), currently housed at the University of Alberta, is a scholarly project to catalogue text analysis applications and create a gateway for researchers new to the practice.\n",
      "Methods for scientific literature mining[edit]\n",
      "Computational methods have been developed to assist with information retrieval from scientific literature. Published approaches include methods for searching,[40] determining novelty,[41] and clarifying homonyms[42] among technical reports.\n",
      "\n",
      "Digital humanities and computational sociology[edit]\n",
      "The automatic analysis of vast textual corpora has created the possibility for scholars to analyze\n",
      "millions of documents in multiple languages with very limited manual intervention. Key enabling technologies have been parsing, machine translation, topic categorization, and machine learning.\n",
      "\n",
      "Narrative network of US Elections 2012[43]\n",
      "The automatic parsing of textual corpora has enabled the extraction of actors and their relational networks on a vast scale, turning textual data into network data. The resulting networks, which can contain thousands of nodes, are then analyzed by using tools from network theory to identify the key actors, the key communities or parties, and general properties such as robustness or structural stability of the overall network, or centrality of certain nodes.[44] This automates the approach introduced by quantitative narrative analysis,[45] whereby subject-verb-object triplets are identified with pairs of actors linked by an action, or pairs formed by actor-object.[43]\n",
      "Content analysis has been a traditional part of social sciences and media studies for a long time. The automation of content analysis has allowed a \"big data\" revolution to take place in that field, with studies in social media and newspaper content that include millions of news items. Gender bias, readability, content similarity, reader preferences, and even mood have been analyzed based on text mining methods over millions of documents.[46][47][48][49][50] The analysis of readability, gender bias and topic bias was demonstrated in Flaounas et al.[51] showing how different topics have different gender biases and levels of readability; the possibility to detect mood patterns in a vast population by analyzing Twitter content was demonstrated as well.[52][53]\n",
      "\n",
      "Software[edit]\n",
      "Main article: List of text mining software\n",
      "Text mining computer programs are available from many commercial and open source companies and sources.\n",
      "\n",
      "Intellectual property law[edit]\n",
      "Situation in Europe[edit]\n",
      "Video by Fix Copyright campaign explaining TDM and its copyright issues in the EU, 2016 [3:51]\n",
      "Under European copyright and database laws, the mining of in-copyright works (such as by web mining) without the permission of the copyright owner is illegal. In the UK in 2014, on the recommendation of the Hargreaves review, the government amended copyright law[54] to allow text mining as a limitation and exception. It was the second country in the world to do so, following Japan, which introduced a mining-specific exception in 2009. However, owing to the restriction of the Information Society Directive (2001), the UK exception only allows content mining for non-commercial purposes. UK copyright law does not allow this provision to be overridden by contractual terms and conditions.\n",
      "The European Commission facilitated stakeholder discussion on text and data mining in 2013, under the title of Licenses for Europe.[55] The fact that the focus on the solution to this legal issue was licenses, and not limitations and exceptions to copyright law, led representatives of universities, researchers, libraries, civil society groups and open access publishers to leave the stakeholder dialogue in May 2013.[56]\n",
      "\n",
      "Situation in the United States[edit]\n",
      "US copyright law, and in particular its fair use provisions, means that text mining in America, as well as other fair use countries such as Israel, Taiwan and South Korea, is viewed as being legal. As text mining is transformative, meaning that it does not supplant the original work, it is viewed as being lawful under fair use. For example, as part of the Google Book settlement the presiding judge on the case ruled that Google's digitization project of in-copyright books was lawful, in part because of the transformative uses that the digitization project displayed—one such use being text and data mining.[57]\n",
      "\n",
      "Situation in Australia[edit]\n",
      "There is no exception in Australian copyright law for text or data mining within the Copyright Act 1968. The Australian Law Reform Commission has noted that it is unlikely that the \"research and study\" fair dealing exception would extend to cover such a topic either, given it would be beyond the \"reasonable portion\" requirement.[58]\n",
      "\n",
      "Implications[edit]\n",
      "Until recently, websites most often used text-based searches, which only found documents containing specific user-defined words or phrases. Now, through use of a semantic web, text mining can find content based on meaning and context (rather than just by a specific word). Additionally, text mining software can be used to build large dossiers of information about specific people and events. For example, large datasets based on data extracted from news reports can be built to facilitate social networks analysis or counter-intelligence. In effect, the text mining software may act in a capacity similar to an intelligence analyst or research librarian, albeit with a more limited scope of analysis. Text mining is also used in some email spam filters as a way of determining the characteristics of messages that are likely to be advertisements or other unwanted material. Text mining plays an important role in determining financial market sentiment.\n",
      "\n",
      "See also[edit]\n",
      "\n",
      "Concept mining\n",
      "Document processing\n",
      "Full text search\n",
      "List of text mining software\n",
      "Market sentiment\n",
      "Name resolution (semantics and text extraction)\n",
      "Named entity recognition\n",
      "News analytics\n",
      "Ontology learning\n",
      "Record linkage\n",
      "Sequential pattern mining (string and sequence mining)\n",
      "w-shingling\n",
      "Web mining, a task that may involve text mining (e.g. first find appropriate web pages by classifying crawled web pages, then extract the desired information from the text content of these pages considered relevant)\n",
      "\n",
      "References[edit]\n",
      "Citations[edit]\n",
      "\n",
      "\n",
      "^ \"Marti Hearst: What is Text Mining?\".\n",
      "\n",
      "^ Hotho, A., Nürnberger, A. and Paaß, G. (2005). \"A brief survey of text mining\". In Ldv Forum, Vol. 20(1), p. 19-62\n",
      "\n",
      "^ Feldman, R. and Sanger, J. (2007). The text mining handbook. Cambridge University Press. New York\n",
      "\n",
      "^ [1] Archived November 29, 2009, at the Wayback Machine\n",
      "\n",
      "^ \"KDD-2000 Workshop on Text Mining – Call for Papers\". Cs.cmu.edu. Retrieved 2015-02-23.\n",
      "\n",
      "^ [2] Archived March 3, 2012, at the Wayback Machine\n",
      "\n",
      "^ Hobbs, Jerry R.; Walker, Donald E.; Amsler, Robert A. (1982). \"Natural language access to structured text\". Proceedings of the 9th conference on Computational linguistics. Vol. 1. pp. 127–32. doi:10.3115/991813.991833. S2CID 6433117.\n",
      "\n",
      "^ \"Unstructured Data and the 80 Percent Rule\". Breakthrough Analysis. August 2008. Retrieved 2015-02-23.\n",
      "\n",
      "^ Antunes, João (2018-11-14). Exploração de informações contextuais para enriquecimento semântico em representações de textos (Mestrado em Ciências de Computação e Matemática Computacional thesis) (in Portuguese). São Carlos: Universidade de São Paulo. doi:10.11606/d.55.2019.tde-03012019-103253.\n",
      "\n",
      "^ Moro, Andrea; Raganato, Alessandro; Navigli, Roberto (December 2014). \"Entity Linking meets Word Sense Disambiguation: a Unified Approach\". Transactions of the Association for Computational Linguistics. 2: 231–244. doi:10.1162/tacl_a_00179. ISSN 2307-387X.\n",
      "\n",
      "^ Chang, Wui Lee; Tay, Kai Meng; Lim, Chee Peng (2017-02-06). \"A New Evolving Tree-Based Model with Local Re-learning for Document Clustering and Visualization\". Neural Processing Letters. 46 (2): 379–409. doi:10.1007/s11063-017-9597-3. ISSN 1370-4621. S2CID 9100902.\n",
      "\n",
      "^ Benchimol, Jonathan; Kazinnik, Sophia; Saadon, Yossi (2022). \"Text mining methodologies with R: An application to central bank texts\". Machine Learning with Applications. 8: 100286. doi:10.1016/j.mlwa.2022.100286. S2CID 243798160.\n",
      "\n",
      "^ Mehl, Matthias R. (2006). \"Quantitative Text Analysis\". Handbook of multimethod measurement in psychology. p. 141. doi:10.1037/11383-011. ISBN 978-1-59147-318-3.\n",
      "\n",
      "^ Pang, Bo; Lee, Lillian (2008). \"Opinion Mining and Sentiment Analysis\". Foundations and Trends in Information Retrieval. 2 (1–2): 1–135. CiteSeerX 10.1.1.147.2755. doi:10.1561/1500000011. ISSN 1554-0669. S2CID 207178694.\n",
      "\n",
      "^ Paltoglou, Georgios; Thelwall, Mike (2012-09-01). \"Twitter, MySpace, Digg: Unsupervised Sentiment Analysis in Social Media\". ACM Transactions on Intelligent Systems and Technology. 3 (4): 66. doi:10.1145/2337542.2337551. ISSN 2157-6904. S2CID 16600444.\n",
      "\n",
      "^ \"Sentiment Analysis in Twitter < SemEval-2017 Task 4\". alt.qcri.org. Retrieved 2018-10-02.\n",
      "\n",
      "^ Zanasi, Alessandro (2009). \"Virtual Weapons for Real Wars: Text Mining for National Security\". Proceedings of the International Workshop on Computational Intelligence in Security for Information Systems CISIS'08. Advances in Soft Computing. Vol. 53. p. 53. doi:10.1007/978-3-540-88181-0_7. ISBN 978-3-540-88180-3.\n",
      "\n",
      "^ Badal, Varsha D.; Kundrotas, Petras J.; Vakser, Ilya A. (2015-12-09). \"Text Mining for Protein Docking\". PLOS Computational Biology. 11 (12): e1004630. Bibcode:2015PLSCB..11E4630B. doi:10.1371/journal.pcbi.1004630. ISSN 1553-7358. PMC 4674139. PMID 26650466.\n",
      "\n",
      "^ Cohen, K. Bretonnel; Hunter, Lawrence (2008). \"Getting Started in Text Mining\". PLOS Computational Biology. 4 (1): e20. Bibcode:2008PLSCB...4...20C. doi:10.1371/journal.pcbi.0040020. PMC 2217579. PMID 18225946.\n",
      "\n",
      "^ Badal, V. D; Kundrotas, P. J; Vakser, I. A (2015). \"Text mining for protein docking\". PLOS Computational Biology. 11 (12): e1004630. Bibcode:2015PLSCB..11E4630B. doi:10.1371/journal.pcbi.1004630. PMC 4674139. PMID 26650466.\n",
      "\n",
      "^ Papanikolaou, Nikolas; Pavlopoulos, Georgios A.; Theodosiou, Theodosios; Iliopoulos, Ioannis (2015). \"Protein–protein interaction predictions using text mining methods\". Methods. 74: 47–53. doi:10.1016/j.ymeth.2014.10.026. ISSN 1046-2023. PMID 25448298.\n",
      "\n",
      "^ Szklarczyk, Damian; Morris, John H; Cook, Helen; Kuhn, Michael; Wyder, Stefan; Simonovic, Milan; Santos, Alberto; Doncheva, Nadezhda T; Roth, Alexander (2016-10-18). \"The STRING database in 2017: quality-controlled protein–protein association networks, made broadly accessible\". Nucleic Acids Research. 45 (D1): D362–D368. doi:10.1093/nar/gkw937. ISSN 0305-1048. PMC 5210637. PMID 27924014.\n",
      "\n",
      "^ Liem, David A.; Murali, Sanjana; Sigdel, Dibakar; Shi, Yu; Wang, Xuan; Shen, Jiaming; Choi, Howard; Caufield, John H.; Wang, Wei; Ping, Peipei; Han, Jiawei (2018-10-01). \"Phrase mining of textual data to analyze extracellular matrix protein patterns across cardiovascular disease\". American Journal of Physiology. Heart and Circulatory Physiology. 315 (4): H910–H924. doi:10.1152/ajpheart.00175.2018. ISSN 1522-1539. PMC 6230912. PMID 29775406.\n",
      "\n",
      "^ Van Le, D; Montgomery, J; Kirkby, KC; Scanlan, J (10 August 2018). \"Risk Prediction using Natural Language Processing of Electronic Mental Health Records in an Inpatient Forensic Psychiatry Setting\". Journal of Biomedical Informatics. 86: 49–58. doi:10.1016/j.jbi.2018.08.007. PMID 30118855.\n",
      "\n",
      "^ Jenssen, Tor-Kristian; Lægreid, Astrid; Komorowski, Jan; Hovig, Eivind (2001). \"A literature network of human genes for high-throughput analysis of gene expression\". Nature Genetics. 28 (1): 21–8. doi:10.1038/ng0501-21. PMID 11326270. S2CID 8889284.\n",
      "\n",
      "^ Masys, Daniel R. (2001). \"Linking microarray data to the literature\". Nature Genetics. 28 (1): 9–10. doi:10.1038/ng0501-9. PMID 11326264. S2CID 52848745.\n",
      "\n",
      "^ Renganathan, Vinaitheerthan (2017). \"Text Mining in Biomedical Domain with Emphasis on Document Clustering\". Healthcare Informatics Research. 23 (3): 141–146. doi:10.4258/hir.2017.23.3.141. ISSN 2093-3681. PMC 5572517. PMID 28875048.\n",
      "\n",
      "^ [3] Archived October 4, 2013, at the Wayback Machine\n",
      "\n",
      "^ \"Text Analytics\". Medallia. Retrieved 2015-02-23.\n",
      "\n",
      "^ a b Coussement, Kristof; Van Den Poel, Dirk (2008). \"Integrating the voice of customers through call center emails into a decision support system for churn prediction\". Information & Management. 45 (3): 164–74. CiteSeerX 10.1.1.113.3238. doi:10.1016/j.im.2008.01.005.\n",
      "\n",
      "^ Coussement, Kristof; Van Den Poel, Dirk (2008). \"Improving customer complaint management by automatic email classification using linguistic style features as predictors\". Decision Support Systems. 44 (4): 870–82. doi:10.1016/j.dss.2007.10.010.\n",
      "\n",
      "^ Ramiro H. Gálvez; Agustín Gravano (2017). \"Assessing the usefulness of online message board mining in automatic stock prediction systems\". Journal of Computational Science. 19: 1877–7503. doi:10.1016/j.jocs.2017.01.001.\n",
      "\n",
      "^ Pang, Bo; Lee, Lillian; Vaithyanathan, Shivakumar (2002). \"Thumbs up?\". Proceedings of the ACL-02 conference on Empirical methods in natural language processing. Vol. 10. pp. 79–86. doi:10.3115/1118693.1118704. S2CID 7105713.\n",
      "\n",
      "^ Alessandro Valitutti; Carlo Strapparava; Oliviero Stock (2005). \"Developing Affective Lexical Resources\" (PDF). PsychNology Journal. 2 (1): 61–83.\n",
      "\n",
      "^ Erik Cambria; Robert Speer; Catherine Havasi; Amir Hussain (2010). \"SenticNet: a Publicly Available Semantic Resource for Opinion Mining\" (PDF). Proceedings of AAAI CSK. pp. 14–18.\n",
      "\n",
      "^ Calvo, Rafael A; d'Mello, Sidney (2010). \"Affect Detection: An Interdisciplinary Review of Models, Methods, and Their Applications\". IEEE Transactions on Affective Computing. 1 (1): 18–37. doi:10.1109/T-AFFC.2010.1. S2CID 753606.\n",
      "\n",
      "^ \"The University of Manchester\". Manchester.ac.uk. Retrieved 2015-02-23.\n",
      "\n",
      "^ \"Tsujii Laboratory\". Tsujii.is.s.u-tokyo.ac.jp. Archived from the original on 2012-03-07. Retrieved 2015-02-23.\n",
      "\n",
      "^ \"The University of Tokyo\". UTokyo. Retrieved 2015-02-23.\n",
      "\n",
      "^ Shen, Jiaming; Xiao, Jinfeng; He, Xinwei; Shang, Jingbo; Sinha, Saurabh; Han, Jiawei (2018-06-27). Entity Set Search of Scientific Literature: An Unsupervised Ranking Approach. ACM. pp. 565–574. doi:10.1145/3209978.3210055. ISBN 978-1-4503-5657-2. S2CID 13748283.\n",
      "\n",
      "^ Walter, Lothar; Radauer, Alfred; Moehrle, Martin G. (2017-02-06). \"The beauty of brimstone butterfly: novelty of patents identified by near environment analysis based on text mining\". Scientometrics. 111 (1): 103–115. doi:10.1007/s11192-017-2267-4. ISSN 0138-9130. S2CID 11174676.\n",
      "\n",
      "^ Roll, Uri; Correia, Ricardo A.; Berger-Tal, Oded (2018-03-10). \"Using machine learning to disentangle homonyms in large text corpora\". Conservation Biology. 32 (3): 716–724. doi:10.1111/cobi.13044. ISSN 0888-8892. PMID 29086438. S2CID 3783779.\n",
      "\n",
      "^ a b Automated analysis of the US presidential elections using Big Data and network analysis; S Sudhahar, GA Veltri, N Cristianini; Big Data & Society 2 (1), 1-28, 2015\n",
      "\n",
      "^ Network analysis of narrative content in large corpora; S Sudhahar, G De Fazio, R Franzosi, N Cristianini; Natural Language Engineering, 1-32, 2013\n",
      "\n",
      "^ Quantitative Narrative Analysis; Roberto Franzosi; Emory University © 2010\n",
      "\n",
      "^ Lansdall-Welfare, Thomas; Sudhahar, Saatviga; Thompson, James; Lewis, Justin; Team, FindMyPast Newspaper; Cristianini, Nello (2017-01-09). \"Content analysis of 150 years of British periodicals\". Proceedings of the National Academy of Sciences. 114 (4): E457–E465. Bibcode:2017PNAS..114E.457L. doi:10.1073/pnas.1606380114. ISSN 0027-8424. PMC 5278459. PMID 28069962.\n",
      "\n",
      "^ I. Flaounas, M. Turchi, O. Ali, N. Fyson, T. De Bie, N. Mosdell, J. Lewis, N. Cristianini, The Structure of EU Mediasphere, PLoS ONE, Vol. 5(12), pp. e14243, 2010.\n",
      "\n",
      "^ Nowcasting Events from the Social Web with Statistical Learning\n",
      "V Lampos, N Cristianini; ACM Transactions on Intelligent Systems and Technology (TIST) 3 (4), 72\n",
      "\n",
      "^ NOAM: news outlets analysis and monitoring system; I Flaounas, O Ali, M Turchi, T Snowsill, F Nicart, T De Bie, N Cristianini Proc. of the 2011 ACM SIGMOD international conference on Management of data\n",
      "\n",
      "^ Automatic discovery of patterns in media content, N Cristianini, Combinatorial Pattern Matching, 2-13, 2011\n",
      "\n",
      "^ I. Flaounas, O. Ali, T. Lansdall-Welfare, T. De Bie, N. Mosdell, J. Lewis, N. Cristianini, RESEARCH METHODS IN THE AGE OF DIGITAL JOURNALISM, Digital Journalism, Routledge, 2012\n",
      "\n",
      "^ Circadian Mood Variations in Twitter Content; Fabon Dzogang, Stafford Lightman, Nello Cristianini. Brain and Neuroscience Advances, 1, 2398212817744501.\n",
      "\n",
      "^ Effects of the Recession on Public Mood in the UK; T Lansdall-Welfare, V Lampos, N Cristianini; Mining Social Network Dynamics (MSND) session on Social Media Applications\n",
      "\n",
      "^ Researchers given data mining right under new UK copyright laws Archived June 9, 2014, at the Wayback Machine\n",
      "\n",
      "^ \"Licences for Europe – Structured Stakeholder Dialogue 2013\". European Commission. Retrieved 14 November 2014.\n",
      "\n",
      "^ \"Text and Data Mining:Its importance and the need for change in Europe\". Association of European Research Libraries. 2013-04-25. Archived from the original on 2014-11-29. Retrieved 14 November 2014.\n",
      "\n",
      "^ \"Judge grants summary judgment in favor of Google Books — a fair use victory\". Lexology. Antonelli Law Ltd. 19 November 2013. Retrieved 14 November 2014.\n",
      "\n",
      "^ \"Text and data mining\". Australian Law Reform Commission. 4 June 2013. Retrieved 10 February 2023.\n",
      "\n",
      "\n",
      "Sources[edit]\n",
      "Ananiadou, S. and McNaught, J. (Editors) (2006). Text Mining for Biology and Biomedicine. Artech House Books. ISBN 978-1-58053-984-5\n",
      "Bilisoly, R. (2008). Practical Text Mining with Perl. New York: John Wiley & Sons. ISBN 978-0-470-17643-6\n",
      "Feldman, R., and Sanger, J. (2006). The Text Mining Handbook. New York: Cambridge University Press. ISBN 978-0-521-83657-9\n",
      "Hotho, A., Nürnberger, A. and Paaß, G. (2005). \"A brief survey of text mining\". In Ldv Forum, Vol. 20(1), p. 19-62\n",
      "Indurkhya, N., and Damerau, F. (2010). Handbook Of Natural Language Processing, 2nd Edition. Boca Raton, FL: CRC Press. ISBN 978-1-4200-8592-1\n",
      "Kao, A., and Poteet, S. (Editors). Natural Language Processing and Text Mining. Springer. ISBN 1-84628-175-X\n",
      "Konchady, M. Text Mining Application Programming (Programming Series). Charles River Media. ISBN 1-58450-460-9\n",
      "Manning, C., and Schutze, H. (1999). Foundations of Statistical Natural Language Processing. Cambridge, MA: MIT Press. ISBN 978-0-262-13360-9\n",
      "Miner, G., Elder, J., Hill. T, Nisbet, R., Delen, D. and Fast, A. (2012). Practical Text Mining and Statistical Analysis for Non-structured Text Data Applications. Elsevier Academic Press. ISBN 978-0-12-386979-1\n",
      "McKnight, W. (2005). \"Building business intelligence: Text data mining in business intelligence\". DM Review, 21-22.\n",
      "Srivastava, A., and Sahami. M. (2009). Text Mining: Classification, Clustering, and Applications. Boca Raton, FL: CRC Press. ISBN 978-1-4200-5940-3\n",
      "Zanasi, A. (Editor) (2007). Text Mining and its Applications to Intelligence, CRM and Knowledge Management. WIT Press. ISBN 978-1-84564-131-3\n",
      "External links[edit]\n",
      "Marti Hearst: What Is Text Mining? (October, 2003)\n",
      "Automatic Content Extraction, Linguistic Data Consortium Archived 2013-09-25 at the Wayback Machine\n",
      "Automatic Content Extraction, NIST\n",
      "vteNatural language processingGeneral terms\n",
      "AI-complete\n",
      "Bag-of-words\n",
      "n-gram\n",
      "Bigram\n",
      "Trigram\n",
      "Computational linguistics\n",
      "Natural-language understanding\n",
      "Stop words\n",
      "Text processing\n",
      "Text analysis\n",
      "Argument mining\n",
      "Collocation extraction\n",
      "Concept mining\n",
      "Coreference resolution\n",
      "Deep linguistic processing\n",
      "Distant reading\n",
      "Information extraction\n",
      "Named-entity recognition\n",
      "Ontology learning\n",
      "Parsing\n",
      "Semantic parsing\n",
      "Syntactic parsing\n",
      "Part-of-speech tagging\n",
      "Semantic analysis\n",
      "Semantic role labeling\n",
      "Semantic decomposition\n",
      "Semantic similarity\n",
      "Sentiment analysis\n",
      "Terminology extraction\n",
      "Text mining\n",
      "Textual entailment\n",
      "Truecasing\n",
      "Word-sense disambiguation\n",
      "Word-sense induction\n",
      "Text segmentation\n",
      "Compound-term processing\n",
      "Lemmatisation\n",
      "Lexical analysis\n",
      "Text chunking\n",
      "Stemming\n",
      "Sentence segmentation\n",
      "Word segmentation\n",
      "\n",
      "Automatic summarization\n",
      "Multi-document summarization\n",
      "Sentence extraction\n",
      "Text simplification\n",
      "Machine translation\n",
      "Computer-assisted\n",
      "Example-based\n",
      "Rule-based\n",
      "Statistical\n",
      "Transfer-based\n",
      "Neural\n",
      "Distributional semantics models\n",
      "BERT\n",
      "Document-term matrix\n",
      "Explicit semantic analysis\n",
      "fastText\n",
      "GloVe\n",
      "Language model (large)\n",
      "Latent semantic analysis\n",
      "Seq2seq\n",
      "Word embedding\n",
      "Word2vec\n",
      "Language resources,datasets and corporaTypes andstandards\n",
      "Corpus linguistics\n",
      "Lexical resource\n",
      "Linguistic Linked Open Data\n",
      "Machine-readable dictionary\n",
      "Parallel text\n",
      "PropBank\n",
      "Semantic network\n",
      "Simple Knowledge Organization System\n",
      "Speech corpus\n",
      "Text corpus\n",
      "Thesaurus (information retrieval)\n",
      "Treebank\n",
      "Universal Dependencies\n",
      "Data\n",
      "BabelNet\n",
      "Bank of English\n",
      "DBpedia\n",
      "FrameNet\n",
      "Google Ngram Viewer\n",
      "UBY\n",
      "WordNet\n",
      "Wikidata\n",
      "Automatic identificationand data capture\n",
      "Speech recognition\n",
      "Speech segmentation\n",
      "Speech synthesis\n",
      "Natural language generation\n",
      "Optical character recognition\n",
      "Topic model\n",
      "Document classification\n",
      "Latent Dirichlet allocation\n",
      "Pachinko allocation\n",
      "Computer-assistedreviewing\n",
      "Automated essay scoring\n",
      "Concordancer\n",
      "Grammar checker\n",
      "Predictive text\n",
      "Pronunciation assessment\n",
      "Spell checker\n",
      "Natural languageuser interface\n",
      "Chatbot\n",
      "Interactive fiction (c.f. Syntax guessing)\n",
      "Question answering\n",
      "Virtual assistant\n",
      "Voice user interface\n",
      "Related\n",
      "Formal semantics\n",
      "Hallucination\n",
      "Natural Language Toolkit\n",
      "spaCy\n",
      "\n",
      "Authority control databases: National \n",
      "Israel\n",
      "Japan\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Retrieved from \"https://en.wikipedia.org/w/index.php?title=Text_mining&oldid=1218530686\"\n",
      "Categories: Text miningApplications of artificial intelligenceApplied data miningComputational linguisticsNatural language processingStatistical natural language processingTextHidden categories: Webarchive template wayback linksCS1 Portuguese-language sources (pt)Articles with short descriptionShort description matches WikidataAll articles with unsourced statementsArticles with unsourced statements from October 2022Articles with J9U identifiersArticles with NDL identifiers\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " This page was last edited on 12 April 2024, at 07:42 (UTC).\n",
      "Text is available under the Creative Commons Attribution-ShareAlike License 4.0;\n",
      "additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization.\n",
      "\n",
      "\n",
      "Privacy policy\n",
      "About Wikipedia\n",
      "Disclaimers\n",
      "Contact Wikipedia\n",
      "Code of Conduct\n",
      "Developers\n",
      "Statistics\n",
      "Cookie statement\n",
      "Mobile view\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_text_from_webpage(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    return soup.get_text()\n",
    "\n",
    "url = 'https://en.wikipedia.org/wiki/Text_mining?wprov=srpw1_0'\n",
    "extracted_text = extract_text_from_webpage(url)\n",
    "print(extracted_text)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
